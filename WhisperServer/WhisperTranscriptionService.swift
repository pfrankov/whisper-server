import Foundation
import whisper
#if os(macOS) || os(iOS)
import SwiftUI
import AVFoundation
#endif

/// Audio transcription service using whisper.cpp
struct WhisperTranscriptionService {
    // MARK: - Audio Conversion
    
    /// Handles conversion of various audio formats to 16-bit, 16kHz mono WAV required by Whisper
    class AudioConverter {
        /// Converts audio data from any supported format to the format required by Whisper
        /// - Parameter audioData: Original audio data in any format (mp3, m4a, ogg, wav, etc.)
        /// - Returns: Converted audio data as PCM 16-bit 16kHz mono samples, or nil if conversion failed
        static func convertToWhisperFormat(_ audioData: Data) -> [Float]? {
            #if os(macOS) || os(iOS)
            return convertUsingAVFoundation(audioData)
            #else
            print("‚ùå Audio conversion is only supported on macOS and iOS")
            return nil
            #endif
        }
        
        #if os(macOS) || os(iOS)
        /// Converts audio using AVFoundation framework - unified approach for all formats
        private static func convertUsingAVFoundation(_ audioData: Data) -> [Float]? {
            print("üîÑ Converting audio to Whisper format (16kHz mono float)")
            
            // Target format: 16kHz mono float
            let targetSampleRate = 16000.0
            let outputFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                           sampleRate: targetSampleRate,
                                           channels: 1,
                                           interleaved: false)!
            
            // Create a temporary file for the input audio
            let tempInputURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent(UUID().uuidString + ".audio")
            
            do {
                // Write input data to temporary file
                try audioData.write(to: tempInputURL)
                
                defer {
                    // Clean up temporary file
                    try? FileManager.default.removeItem(at: tempInputURL)
                }
                
                // Try to create an AVAudioFile from the data
                guard let audioFile = try? AVAudioFile(forReading: tempInputURL) else {
                    print("‚ùå Failed to create AVAudioFile for reading")
                    return nil
                }
                
                let sourceFormat = audioFile.processingFormat
                print("üîç Source format: \(sourceFormat.sampleRate)Hz, \(sourceFormat.channelCount) channels")
                
                // Convert the audio file to the required format
                return convertAudioFile(audioFile, toFormat: outputFormat)
            } catch {
                print("‚ùå Failed during audio file preparation: \(error.localizedDescription)")
                return nil
            }
        }
        
        /// Converts an audio file to the specified format
        private static func convertAudioFile(_ file: AVAudioFile, toFormat outputFormat: AVAudioFormat) -> [Float]? {
            let sourceFormat = file.processingFormat
            let frameCount = AVAudioFrameCount(file.length)
            
            // If the file is empty, return nil
            if frameCount == 0 {
                print("‚ùå Audio file is empty")
                return nil
            }
            
            // Read the entire file into a buffer
                guard let buffer = AVAudioPCMBuffer(pcmFormat: sourceFormat, frameCapacity: frameCount) else {
                print("‚ùå Failed to create source PCM buffer")
                return nil
            }
            
            do {
                try file.read(into: buffer)
                } catch {
                print("‚ùå Failed to read audio file: \(error.localizedDescription)")
                return nil
            }
            
            // If source format matches target format, just return the samples
            if abs(sourceFormat.sampleRate - outputFormat.sampleRate) < 1.0 && 
               sourceFormat.channelCount == outputFormat.channelCount {
                return extractSamplesFromBuffer(buffer)
        }
            
            // Create converter and convert
            guard let converter = AVAudioConverter(from: sourceFormat, to: outputFormat) else {
                print("‚ùå Failed to create audio converter")
                return nil
            }
            
            // Calculate output buffer size with some margin
            let ratio = outputFormat.sampleRate / sourceFormat.sampleRate
            let outputFrameCapacity = AVAudioFrameCount(Double(frameCount) * ratio * 1.1)
            
            guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: outputFrameCapacity) else {
                print("‚ùå Failed to create output buffer")
                return nil
            }
            
            // Perform conversion
            var error: NSError?
            let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
                outStatus.pointee = .haveData
                return buffer
            }
            
            let status = converter.convert(to: outputBuffer, error: &error, withInputFrom: inputBlock)
            
            if status == .error || error != nil {
                print("‚ùå Conversion failed: \(error?.localizedDescription ?? "unknown error")")
                return nil
            }
            
            if outputBuffer.frameLength == 0 {
                print("‚ùå No frames were converted")
                return nil
            }
            
            print("‚úÖ Successfully converted to \(outputBuffer.frameLength) frames at \(outputFormat.sampleRate)Hz")
            
            return extractSamplesFromBuffer(outputBuffer)
        }
        
        /// Extracts float samples from an audio buffer
        private static func extractSamplesFromBuffer(_ buffer: AVAudioPCMBuffer) -> [Float]? {
            guard let channelData = buffer.floatChannelData, buffer.frameLength > 0 else {
                print("‚ùå No valid channel data in buffer")
                return nil
            }
            
            // Extract samples from the first channel (mono)
            let data = UnsafeBufferPointer(start: channelData[0], count: Int(buffer.frameLength))
            return Array(data)
        }
        #endif
    }

    // –†–∞–∑–¥–µ–ª—è–µ–º—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    private static var sharedContext: OpaquePointer?
    private static let lock = NSLock()
    
    /// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
    private static func setupMetalShaderCache() {
        #if os(macOS) || os(iOS)
        // –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ —à–µ–π–¥–µ—Ä–æ–≤ Metal
        var cacheDirectory: URL
        
        // –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∫—ç—à–µ–º –≤ Application Support
        if let appSupportDir = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first {
            let bundleId = Bundle.main.bundleIdentifier ?? "com.whisperserver"
            let whisperCacheDir = appSupportDir.appendingPathComponent(bundleId).appendingPathComponent("MetalCache")
            
            // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            do {
                try FileManager.default.createDirectory(at: whisperCacheDir, withIntermediateDirectories: true)
                cacheDirectory = whisperCacheDir
                print("‚úÖ Set Metal shader cache directory: \(whisperCacheDir.path)")
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –∫—ç—à
                let fileManager = FileManager.default
                let cacheFolderContents = try? fileManager.contentsOfDirectory(at: whisperCacheDir, includingPropertiesForKeys: nil)
                if let contents = cacheFolderContents, !contents.isEmpty {
                    print("üìã Found existing Metal cache with \(contents.count) files")
                }
            } catch {
                print("‚ö†Ô∏è Failed to create Metal cache directory: \(error.localizedDescription)")
                // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
                cacheDirectory = FileManager.default.temporaryDirectory.appendingPathComponent("WhisperMetalCache")
            }
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Metal
            setenv("MTL_SHADER_CACHE_PATH", cacheDirectory.path, 1)
            setenv("MTL_SHADER_CACHE", "1", 1)
            setenv("MTL_SHADER_CACHE_SKIP_VALIDATION", "1", 1)
            
            // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            #if DEBUG
            setenv("MTL_DEBUG_SHADER_CACHE", "1", 1)
            #endif
        }
        #endif
    }
    
    /// –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    static func cleanup() {
        lock.lock(); defer { lock.unlock() }
        if let ctx = sharedContext {
            whisper_free(ctx)
            sharedContext = nil
            print("üßπ Whisper context released")
        }
    }
    
    /// –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –∏ –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç Whisper –ø—Ä–∏ —Å–º–µ–Ω–µ –º–æ–¥–µ–ª–∏
    static func reinitializeContext() {
        // –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        lock.lock()
        if let ctx = sharedContext {
            whisper_free(ctx)
            sharedContext = nil
            print("üîÑ Whisper context released for model change")
        }
        lock.unlock()
        
        // –ö–æ–Ω—Ç–µ–∫—Å—Ç –±—É–¥–µ—Ç –ø–µ—Ä–µ–∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º –≤—ã–∑–æ–≤–µ transcribeAudioData
        // –∏–ª–∏ preloadModelForShaderCaching –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        print("‚úÖ Context will be reinitialized on next use with new model")
    }
    
    /// –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Returns: True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
    static func preloadModelForShaderCaching(modelBinPath: URL? = nil, modelEncoderDir: URL? = nil) -> Bool {
        lock.lock(); defer { lock.unlock() }
        
        // –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
        if sharedContext != nil {
            print("‚úÖ Context already initialized, reusing")
            return true
        }
        
        print("üîÑ Preloading Whisper model for shader caching")
        
        #if os(macOS) || os(iOS)
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
        setupMetalShaderCache()
        #endif
        
        // Get model paths either from parameters or try to get from AppDelegate
        var binPath: URL?
        
        if let providedBinPath = modelBinPath {
            // Use directly provided path 
            binPath = providedBinPath
        } else {
            // Fallback to getting from AppDelegate - but now this won't be called from background thread
            print("üîÑ Attempting to get paths from ModelManager via AppDelegate...")
            DispatchQueue.main.sync {
                if let appDelegate = NSApplication.shared.delegate as? AppDelegate {
                    if let modelPaths = appDelegate.modelManager.getPathsForSelectedModel() {
                        binPath = modelPaths.binPath
                    }
                }
            }
        }
        
        guard let binPath = binPath else {
            print("‚ùå Failed to get model bin path")
            return false
        }
        
        print("üìÇ Using model file at: \(binPath.path)")
        
        // Verify file exists and can be accessed
        let fileManager = FileManager.default
        if !fileManager.fileExists(atPath: binPath.path) {
            print("‚ùå Model file doesn't exist at: \(binPath.path)")
            return false
        }
        
        if !fileManager.isReadableFile(atPath: binPath.path) {
            print("‚ùå Model file isn't readable at: \(binPath.path)")
            return false
        }
        
        var isDirectory: ObjCBool = false
        if fileManager.fileExists(atPath: binPath.path, isDirectory: &isDirectory) && isDirectory.boolValue {
            print("‚ùå Path exists but is a directory, not a file: \(binPath.path)")
            return false
        }
        
        // Log file size for debugging
        do {
            let attributes = try fileManager.attributesOfItem(atPath: binPath.path)
            if let fileSize = attributes[.size] as? UInt64 {
                print("üìÑ File size: \(fileSize) bytes")
                if fileSize < 1000000 { // At least 1MB for a model file
                    print("‚ö†Ô∏è Warning: Model file is suspiciously small")
                }
            } else {
                print("üìÑ File size: unknown")
            }
        } catch {
            print("üìÑ File size: could not be determined - \(error.localizedDescription)")
        }
        
        // Additional verification: try to read a bit of the file
        do {
            let fileHandle = try FileHandle(forReadingFrom: binPath)
            let header = try fileHandle.read(upToCount: 16)
            try fileHandle.close()
            
            if header == nil || header!.isEmpty {
                print("‚ùå Could not read file header - file may be empty or inaccessible")
                return false
            }
            
            print("‚úÖ Successfully read file header")
        } catch {
            print("‚ùå Error reading file: \(error.localizedDescription)")
            return false
        }
        
        var contextParams = whisper_context_default_params()
        #if os(macOS) || os(iOS)
        contextParams.use_gpu = true
        contextParams.flash_attn = true
        
        // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Metal
        setenv("WHISPER_METAL_NDIM", "128", 1)  // –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ä—Ç–∏–∏
        setenv("WHISPER_METAL_MEM_MB", "1024", 1) // –í—ã–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è Metal
        print("üîß Metal settings: NDIM=128, MEM_MB=1024")
        #endif
        
        print("üîÑ Initializing Whisper context with file...")
        let contextResult = whisper_init_from_file_with_params(binPath.path, contextParams)
        
        if contextResult == nil {
            print("‚ùå Failed to initialize Whisper context - null result returned")
            return false
        }
        
        sharedContext = contextResult
        print("‚úÖ Whisper context initialized successfully")
        return true
    }
    
    /// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç Whisper —Å —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–º–∏ –ø—É—Ç—è–º–∏ –∫ –º–æ–¥–µ–ª–∏
    private static func initializeContext(binPath: URL) -> OpaquePointer? {
        print("üîÑ Initializing Whisper context with provided model path")
        
        #if os(macOS) || os(iOS)
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
        setupMetalShaderCache()
        #endif
        
        print("üìÇ Using model file at: \(binPath.path)")
        
        // Verify file exists and can be accessed
        let fileManager = FileManager.default
        guard fileManager.fileExists(atPath: binPath.path),
              fileManager.isReadableFile(atPath: binPath.path) else {
            print("‚ùå Model file doesn't exist or isn't readable at: \(binPath.path)")
            return nil
        }
        
        // Log file size for debugging
        do {
            let attributes = try fileManager.attributesOfItem(atPath: binPath.path)
            if let fileSize = attributes[.size] as? UInt64 {
                print("üìÑ File size: \(fileSize) bytes")
            } else {
                print("üìÑ File size: unknown")
            }
        } catch {
            print("üìÑ File size: could not be determined - \(error.localizedDescription)")
        }
        
        var contextParams = whisper_context_default_params()
        
        #if os(macOS) || os(iOS)
        contextParams.use_gpu = true
        contextParams.flash_attn = true
        
        // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Metal
        setenv("WHISPER_METAL_NDIM", "128", 1)  // –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ä—Ç–∏–∏
        setenv("WHISPER_METAL_MEM_MB", "1024", 1) // –í—ã–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è Metal
        print("üîß Metal settings: NDIM=128, MEM_MB=1024")
        #endif
        
        print("üîÑ Initializing Whisper context with file...")
        guard let newContext = whisper_init_from_file_with_params(binPath.path, contextParams) else {
            print("‚ùå Failed to initialize Whisper context")
            return nil
        }
        
        print("‚úÖ Whisper context initialized successfully")
        return newContext
    }
    
    /// Performs transcription of audio data received from HTTP request and returns the result
    /// - Parameters:
    ///   - audioData: Binary audio file data
    ///   - language: Audio language code (optional, by default determined automatically)
    ///   - prompt: Prompt to improve recognition (optional)
    ///   - modelPaths: Optional model paths to use for initialization if context doesn't exist
    /// - Returns: String with transcription result or nil in case of error
    static func transcribeAudioData(_ audioData: Data, language: String? = nil, prompt: String? = nil, modelPaths: (binPath: URL, encoderDir: URL)? = nil) -> String? {
        // –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        let context: OpaquePointer
        
        lock.lock()
        
        // Check if we have an existing context
        if let existingContext = sharedContext {
            print("‚úÖ Using existing Whisper context")
            context = existingContext
            lock.unlock()
        } else {
            // We need to initialize a new context
            print("üîÑ Initializing Whisper context (this may take a while on first run)")
            
            // Determine how to get model paths - either use the provided paths or fail
            if let paths = modelPaths {
                print("üîÑ Using provided model paths for initialization:")
                print("   - Bin path: \(paths.binPath.path)")
                print("   - Encoder dir: \(paths.encoderDir.path)")
                
                // Verify that the files exist and are readable
                let fileManager = FileManager.default
                if !fileManager.fileExists(atPath: paths.binPath.path) {
                    lock.unlock()
                    print("‚ùå Model bin file does not exist at path: \(paths.binPath.path)")
                    return nil
                }
                
                if !fileManager.isReadableFile(atPath: paths.binPath.path) {
                    lock.unlock()
                    print("‚ùå Model bin file is not readable at path: \(paths.binPath.path)")
                    return nil
                }
                
                // Initialize context with the provided bin path
                guard let newContext = initializeContext(binPath: paths.binPath) else {
                    lock.unlock()
                    print("‚ùå Failed to initialize Whisper context with provided paths")
                    return nil
                }
                
                sharedContext = newContext
                context = newContext
                print("‚úÖ Successfully initialized new Whisper context with provided model paths")
                lock.unlock()
            } else {
                // We don't have model paths and we're in a background thread - cannot proceed
                lock.unlock()
                print("‚ùå No model paths provided and cannot access AppDelegate from background thread")
                return nil
            }
        }
        
        // Configure parameters
        var params = whisper_full_default_params(WHISPER_SAMPLING_GREEDY)
        params.print_realtime = false
        params.print_progress = false
        params.print_timestamps = false
        params.print_special = false
        params.translate = false
        params.no_context = true
        
        // Set language if specified
        if let language = language {
            language.withCString { lang in
                params.language = lang
            }
        }
        
        // Set prompt if specified
        if let prompt = prompt {
            prompt.withCString { p in
                params.initial_prompt = p
            }
        }
        
        // Use available CPU cores efficiently
        params.n_threads = Int32(max(1, min(8, ProcessInfo.processInfo.processorCount - 2)))
        
        // Convert audio to samples for Whisper using the new converter
        guard let samples = AudioConverter.convertToWhisperFormat(audioData) else {
            print("‚ùå Failed to convert audio data to Whisper format")
            return nil
        }
        
        // Start transcription
        var result: Int32 = -1
        samples.withUnsafeBufferPointer { samples in
            result = whisper_full(context, params, samples.baseAddress, Int32(samples.count))
        }
        
        if result != 0 {
            print("‚ùå Error during transcription execution")
            return nil
        }
        
        // Collect results
        let numSegments = whisper_full_n_segments(context)
        var transcription = ""
        
        for i in 0..<numSegments {
            transcription += String(cString: whisper_full_get_segment_text(context, i))
        }
        
        return transcription.trimmingCharacters(in: .whitespacesAndNewlines)
    }
}
