import Foundation
import whisper
#if os(macOS) || os(iOS)
import SwiftUI
import AVFoundation
#endif

/// Audio transcription service using whisper.cpp
struct WhisperTranscriptionService {
    // MARK: - Audio Conversion
    
    /// Handles conversion of various audio formats to 16-bit, 16kHz mono WAV required by Whisper
    class AudioConverter {
        /// Converts audio data from any supported format to the format required by Whisper
        /// - Parameter audioData: Original audio data in any format (mp3, m4a, ogg, wav, etc.)
        /// - Returns: Converted audio data as PCM 16-bit 16kHz mono samples, or nil if conversion failed
        static func convertToWhisperFormat(_ audioData: Data) -> [Float]? {
            #if os(macOS) || os(iOS)
            return convertUsingAVFoundation(audioData)
            #else
            print("‚ùå Audio conversion is only supported on macOS and iOS")
            return nil
            #endif
        }
        
        #if os(macOS) || os(iOS)
        /// Converts audio using AVFoundation framework - unified approach for all formats
        private static func convertUsingAVFoundation(_ audioData: Data) -> [Float]? {
            print("üîÑ Converting audio to Whisper format (16kHz mono float)")
            
            // Target format: 16kHz mono float
            let targetSampleRate = 16000.0
            let outputFormat = AVAudioFormat(commonFormat: .pcmFormatFloat32,
                                           sampleRate: targetSampleRate,
                                           channels: 1,
                                           interleaved: false)!
            
            // Create a temporary file for the input audio
            let tempInputURL = URL(fileURLWithPath: NSTemporaryDirectory()).appendingPathComponent(UUID().uuidString + ".audio")
            
            do {
                // Write input data to temporary file
                try audioData.write(to: tempInputURL)
                
                defer {
                    // Clean up temporary file
                    try? FileManager.default.removeItem(at: tempInputURL)
                }
                
                // Try to create an AVAudioFile from the data
                guard let audioFile = try? AVAudioFile(forReading: tempInputURL) else {
                    print("‚ùå Failed to create AVAudioFile for reading")
                    return nil
                }
                
                let sourceFormat = audioFile.processingFormat
                print("üîç Source format: \(sourceFormat.sampleRate)Hz, \(sourceFormat.channelCount) channels")
                
                // Convert the audio file to the required format
                return convertAudioFile(audioFile, toFormat: outputFormat)
            } catch {
                print("‚ùå Failed during audio file preparation: \(error.localizedDescription)")
                return nil
            }
        }
        
        /// Converts an audio file to the specified format
        private static func convertAudioFile(_ file: AVAudioFile, toFormat outputFormat: AVAudioFormat) -> [Float]? {
            let sourceFormat = file.processingFormat
            let frameCount = AVAudioFrameCount(file.length)
            
            // If the file is empty, return nil
            if frameCount == 0 {
                print("‚ùå Audio file is empty")
                return nil
            }
            
            // Read the entire file into a buffer
                guard let buffer = AVAudioPCMBuffer(pcmFormat: sourceFormat, frameCapacity: frameCount) else {
                print("‚ùå Failed to create source PCM buffer")
                return nil
            }
            
            do {
                try file.read(into: buffer)
                } catch {
                print("‚ùå Failed to read audio file: \(error.localizedDescription)")
                return nil
            }
            
            // If source format matches target format, just return the samples
            if abs(sourceFormat.sampleRate - outputFormat.sampleRate) < 1.0 && 
               sourceFormat.channelCount == outputFormat.channelCount {
                return extractSamplesFromBuffer(buffer)
        }
            
            // Create converter and convert
            guard let converter = AVAudioConverter(from: sourceFormat, to: outputFormat) else {
                print("‚ùå Failed to create audio converter")
                return nil
            }
            
            // Calculate output buffer size with some margin
            let ratio = outputFormat.sampleRate / sourceFormat.sampleRate
            let outputFrameCapacity = AVAudioFrameCount(Double(frameCount) * ratio * 1.1)
            
            guard let outputBuffer = AVAudioPCMBuffer(pcmFormat: outputFormat, frameCapacity: outputFrameCapacity) else {
                print("‚ùå Failed to create output buffer")
                return nil
            }
            
            // Perform conversion
            var error: NSError?
            let inputBlock: AVAudioConverterInputBlock = { inNumPackets, outStatus in
                outStatus.pointee = .haveData
                return buffer
            }
            
            let status = converter.convert(to: outputBuffer, error: &error, withInputFrom: inputBlock)
            
            if status == .error || error != nil {
                print("‚ùå Conversion failed: \(error?.localizedDescription ?? "unknown error")")
                return nil
            }
            
            if outputBuffer.frameLength == 0 {
                print("‚ùå No frames were converted")
                return nil
            }
            
            print("‚úÖ Successfully converted to \(outputBuffer.frameLength) frames at \(outputFormat.sampleRate)Hz")
            
            return extractSamplesFromBuffer(outputBuffer)
        }
        
        /// Extracts float samples from an audio buffer
        private static func extractSamplesFromBuffer(_ buffer: AVAudioPCMBuffer) -> [Float]? {
            guard let channelData = buffer.floatChannelData, buffer.frameLength > 0 else {
                print("‚ùå No valid channel data in buffer")
                return nil
            }
            
            // Extract samples from the first channel (mono)
            let data = UnsafeBufferPointer(start: channelData[0], count: Int(buffer.frameLength))
            return Array(data)
        }
        #endif
    }

    // –†–∞–∑–¥–µ–ª—è–µ–º—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –º–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
    private static var sharedContext: OpaquePointer?
    private static let lock = NSLock()
    
    /// –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
    private static func setupMetalShaderCache() {
        #if os(macOS) || os(iOS)
        // –ü–∞–ø–∫–∞ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∞ —à–µ–π–¥–µ—Ä–æ–≤ Metal
        var cacheDirectory: URL
        
        // –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å –∫—ç—à–µ–º –≤ Application Support
        if let appSupportDir = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first {
            let bundleId = Bundle.main.bundleIdentifier ?? "com.whisperserver"
            let whisperCacheDir = appSupportDir.appendingPathComponent(bundleId).appendingPathComponent("MetalCache")
            
            // –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            do {
                try FileManager.default.createDirectory(at: whisperCacheDir, withIntermediateDirectories: true)
                cacheDirectory = whisperCacheDir
                print("‚úÖ Set Metal shader cache directory: \(whisperCacheDir.path)")
                
                // –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —É–∂–µ –∫—ç—à
                let fileManager = FileManager.default
                let cacheFolderContents = try? fileManager.contentsOfDirectory(at: whisperCacheDir, includingPropertiesForKeys: nil)
                if let contents = cacheFolderContents, !contents.isEmpty {
                    print("üìã Found existing Metal cache with \(contents.count) files")
                }
            } catch {
                print("‚ö†Ô∏è Failed to create Metal cache directory: \(error.localizedDescription)")
                // –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∫–∞–∫ –∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
                cacheDirectory = FileManager.default.temporaryDirectory.appendingPathComponent("WhisperMetalCache")
            }
            
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è Metal
            setenv("MTL_SHADER_CACHE_PATH", cacheDirectory.path, 1)
            setenv("MTL_SHADER_CACHE", "1", 1)
            setenv("MTL_SHADER_CACHE_SKIP_VALIDATION", "1", 1)
            
            // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
            #if DEBUG
            setenv("MTL_DEBUG_SHADER_CACHE", "1", 1)
            #endif
        }
        #endif
    }
    
    /// –û—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏ —Ä–∞–±–æ—Ç—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    static func cleanup() {
        lock.lock(); defer { lock.unlock() }
        if let ctx = sharedContext {
            whisper_free(ctx)
            sharedContext = nil
            print("üßπ Whisper context released")
        }
    }
    
    /// –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫—É –∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
    /// - Returns: True –µ—Å–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞
    static func preloadModelForShaderCaching() -> Bool {
        lock.lock(); defer { lock.unlock() }
        
        // –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —É—Å–ø–µ—Ö
        if sharedContext != nil {
            return true
        }
        
        print("üîÑ Preloading Whisper model for shader caching")
        
        #if os(macOS) || os(iOS)
        // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
        setupMetalShaderCache()
        #endif
        
        guard let modelURL = Bundle.main.url(forResource: "ggml-large-v3-turbo-q5_0", withExtension: "bin") else {
            print("‚ùå Failed to find Whisper model")
            return false
        }
        
        var contextParams = whisper_context_default_params()
        #if os(macOS) || os(iOS)
        contextParams.use_gpu = true
        contextParams.flash_attn = true
        
        // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Metal
        setenv("WHISPER_METAL_NDIM", "128", 1)  // –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ä—Ç–∏–∏
        setenv("WHISPER_METAL_MEM_MB", "1024", 1) // –í—ã–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è Metal
        #endif
        
        guard let newContext = whisper_init_from_file_with_params(modelURL.path, contextParams) else {
            print("‚ùå Failed to initialize Whisper context")
            return false
        }
        
        sharedContext = newContext
        print("‚úÖ Whisper context initialized successfully")
        return true
    }
    
    /// Performs transcription of audio data received from HTTP request and returns the result
    /// - Parameters:
    ///   - audioData: Binary audio file data
    ///   - language: Audio language code (optional, by default determined automatically)
    ///   - prompt: Prompt to improve recognition (optional)
    /// - Returns: String with transcription result or nil in case of error
    static func transcribeAudioData(_ audioData: Data, language: String? = nil, prompt: String? = nil) -> String? {
        // –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        let context: OpaquePointer
        
        lock.lock()
        if let existingContext = sharedContext {
            context = existingContext
            lock.unlock()
        } else {
            // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
            print("üîÑ Initializing Whisper context (this may take a while on first run)")
            
            #if os(macOS) || os(iOS)
            // –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ø–æ—Å—Ç–æ—è–Ω–Ω—ã–π –∫—ç—à —à–µ–π–¥–µ—Ä–æ–≤ Metal
            setupMetalShaderCache()
            #endif
        
            
            guard let modelURL = Bundle.main.url(forResource: "ggml-large-v3-turbo", withExtension: "bin") else {
                lock.unlock()
                print("‚ùå Failed to find Whisper model")
                return nil
            }
            
            var contextParams = whisper_context_default_params()
            #if os(macOS) || os(iOS)
            contextParams.use_gpu = true
            contextParams.flash_attn = true
            
            // –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –¥–ª—è Metal
            setenv("WHISPER_METAL_NDIM", "128", 1)  // –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑–º–µ—Ä–∞ –ø–∞—Ä—Ç–∏–∏
            setenv("WHISPER_METAL_MEM_MB", "1024", 1) // –í—ã–¥–µ–ª–µ–Ω–∏–µ –±–æ–ª—å—à–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø–∞–º—è—Ç–∏ –¥–ª—è Metal
            #endif
            
            guard let newContext = whisper_init_from_file_with_params(modelURL.path, contextParams) else {
                lock.unlock()
                print("‚ùå Failed to initialize Whisper context")
                return nil
            }
            
            sharedContext = newContext
            context = newContext
            print("‚úÖ Whisper context initialized successfully")
            lock.unlock()
        }
        
        // Configure parameters
        var params = whisper_full_default_params(WHISPER_SAMPLING_GREEDY)
        params.print_realtime = false
        params.print_progress = false
        params.print_timestamps = false
        params.print_special = false
        params.translate = false
        params.no_context = true
        
        // Set language if specified
        if let language = language {
            language.withCString { lang in
                params.language = lang
            }
        }
        
        // Set prompt if specified
        if let prompt = prompt {
            prompt.withCString { p in
                params.initial_prompt = p
            }
        }
        
        // Use available CPU cores efficiently
        params.n_threads = Int32(max(1, min(8, ProcessInfo.processInfo.processorCount - 2)))
        
        // Convert audio to samples for Whisper using the new converter
        guard let samples = AudioConverter.convertToWhisperFormat(audioData) else {
            print("‚ùå Failed to convert audio data to Whisper format")
            return nil
        }
        
        // Start transcription
        var result: Int32 = -1
        samples.withUnsafeBufferPointer { samples in
            result = whisper_full(context, params, samples.baseAddress, Int32(samples.count))
        }
        
        if result != 0 {
            print("‚ùå Error during transcription execution")
            return nil
        }
        
        // Collect results
        let numSegments = whisper_full_n_segments(context)
        var transcription = ""
        
        for i in 0..<numSegments {
            transcription += String(cString: whisper_full_get_segment_text(context, i))
        }
        
        return transcription.trimmingCharacters(in: .whitespacesAndNewlines)
    }
}
